# æ–°å»º predict_sahi.py
from ultralytics import RTDETR
from sahi import AutoDetectionModel
from sahi.predict import get_sliced_prediction
import cv2
import os


def main():
    # 1. å‡†å¤‡è·¯å¾„
    weight_path = 'W-RT-DETR-Runs/visdrone_exp_v1/weights/best.pt'
    image_path = 'datasets/VisDrone2019-DET/VisDrone2019-DET-test-dev/images/0000006_00159_d_0000007.jpg'

    # 2. åŒ…è£…ä½ çš„ W-RT-DETR æ¨¡å‹ç»™ SAHI ä½¿ç”¨
    # SAHI é»˜è®¤æ”¯æŒ YOLOï¼Œæˆ‘ä»¬éœ€è¦ç”¨è¿™ç§æ–¹å¼è®©å®ƒæ”¯æŒ RT-DETR
    detection_model = AutoDetectionModel.from_pretrained(
        model_type='yolov8',  # å€Ÿç”¨æ¥å£
        model_path=weight_path,
        confidence_threshold=0.25,
        device="cuda:0",  # æˆ– 'cpu'
    )

    # 3. æ ¸å¿ƒï¼šåˆ‡ç‰‡æ¨ç†
    # slice_height/width: åˆ‡ç‰‡å¤§å°ï¼Œå»ºè®®å’Œè®­ç»ƒæ—¶çš„ imgsz ä¸€è‡´ (640)
    # overlap_height_ratio: é‡å ç‡ï¼Œé˜²æ­¢åˆ‡æ–­ç‰©ä½“
    print("ğŸš€ å¼€å§‹åˆ‡ç‰‡æ¨ç† (è¿™å¯èƒ½æ¯”æ™®é€šæ¨ç†æ…¢ï¼Œä½†æ›´ç²¾å‡†)...")
    result = get_sliced_prediction(
        image_path,
        detection_model,
        slice_height=640,
        slice_width=640,
        overlap_height_ratio=0.2,
        overlap_width_ratio=0.2
    )

    # 4. ä¿å­˜ç»“æœ
    save_path = "sahi_result.jpg"
    result.export_visuals(export_dir=".", file_name="sahi_result")
    print(f"âœ… SAHI æ¨ç†å®Œæˆï¼ç»“æœå›¾å·²ä¿å­˜ä¸º: {save_path}")


if __name__ == '__main__':
    main()